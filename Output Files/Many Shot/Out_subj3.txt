DEVICE = cuda
Validation Accuracy: [1 : 38.39286] [2 : 25.89286] [3 : nan] [4 : 31.25000] [5 : 25.00000] [6 : 33.92857] [7 : 30.35714] [8 : 34.82143] [9 : 28.57143]
validation loss: [1 : 1.25586] [2 : 1.72725] [3 : nan] [4 : 1.41075] [5 : 1.83161] [6 : 1.40959] [7 : 1.38190] [8 : 1.39932] [9 : 1.75795]
train loss: [1 : 1.19617] [2 : 1.47212] [3 : nan] [4 : 1.32314] [5 : 1.40118] [6 : 1.39126] [7 : 1.32542] [8 : 1.22883] [9 : 1.16175]
Epoch 1: 	validation acc: 31.02679	validation loss: 1.521779	train loss: 1.312483
Validation Accuracy: [1 : 42.85714] [2 : 24.10714] [3 : nan] [4 : 32.14286] [5 : 25.00000] [6 : 36.60714] [7 : 25.00000] [8 : 45.53571] [9 : 33.92857]
validation loss: [1 : 1.08500] [2 : 1.82506] [3 : nan] [4 : 1.51192] [5 : 2.21006] [6 : 1.55077] [7 : 1.60511] [8 : 1.24217] [9 : 1.75843]
train loss: [1 : 1.02610] [2 : 1.44350] [3 : nan] [4 : 1.26106] [5 : 1.39788] [6 : 1.38566] [7 : 1.29865] [8 : 1.12209] [9 : 1.04206]
Epoch 2: 	validation acc: 33.14732	validation loss: 1.598564	train loss: 1.247124
Validation Accuracy: [1 : 55.35714] [2 : 24.10714] [3 : nan] [4 : 31.25000] [5 : 25.89286] [6 : 37.50000] [7 : 28.57143] [8 : 49.10714] [9 : 37.50000]
validation loss: [1 : 0.91817] [2 : 1.86374] [3 : nan] [4 : 1.46113] [5 : 2.21710] [6 : 1.41744] [7 : 1.48925] [8 : 1.06981] [9 : 1.51190]
train loss: [1 : 0.91832] [2 : 1.41509] [3 : nan] [4 : 1.22204] [5 : 1.42695] [6 : 1.31851] [7 : 1.27595] [8 : 1.02416] [9 : 1.01632]
Epoch 3: 	validation acc: 36.16071	validation loss: 1.493568	train loss: 1.202167
Validation Accuracy: [1 : 51.78571] [2 : 25.00000] [3 : nan] [4 : 34.82143] [5 : 27.67857] [6 : 31.25000] [7 : 32.14286] [8 : 57.14286] [9 : 39.28571]
validation loss: [1 : 0.90235] [2 : 1.94433] [3 : nan] [4 : 1.46276] [5 : 2.33063] [6 : 1.56534] [7 : 1.51140] [8 : 1.04428] [9 : 1.69579]
train loss: [1 : 0.86923] [2 : 1.39173] [3 : nan] [4 : 1.14998] [5 : 1.39078] [6 : 1.27532] [7 : 1.25452] [8 : 0.96744] [9 : 0.94117]
Epoch 4: 	validation acc: 37.38839	validation loss: 1.557111	train loss: 1.155022
Validation Accuracy: [1 : 53.57143] [2 : 25.00000] [3 : nan] [4 : 40.17857] [5 : 25.00000] [6 : 35.71429] [7 : 30.35714] [8 : 62.50000] [9 : 42.85714]
validation loss: [1 : 0.86724] [2 : 2.01995] [3 : nan] [4 : 1.48182] [5 : 2.39845] [6 : 1.49431] [7 : 1.50681] [8 : 0.94627] [9 : 1.46301]
train loss: [1 : 0.79793] [2 : 1.35967] [3 : nan] [4 : 1.14495] [5 : 1.34711] [6 : 1.27585] [7 : 1.22877] [8 : 0.93917] [9 : 0.94060]
Epoch 5: 	validation acc: 39.39732	validation loss: 1.522233	train loss: 1.129255
Validation Accuracy: [1 : 58.92857] [2 : 33.03571] [3 : nan] [4 : 37.50000] [5 : 25.00000] [6 : 34.82143] [7 : 28.57143] [8 : 66.96429] [9 : 46.42857]
validation loss: [1 : 0.81792] [2 : 1.96133] [3 : nan] [4 : 1.44312] [5 : 2.51796] [6 : 1.43514] [7 : 1.49152] [8 : 0.90677] [9 : 1.39773]
train loss: [1 : 0.78349] [2 : 1.33417] [3 : nan] [4 : 1.15212] [5 : 1.31778] [6 : 1.25223] [7 : 1.14366] [8 : 0.90050] [9 : 0.91043]
Epoch 6: 	validation acc: 41.40625	validation loss: 1.496437	train loss: 1.099296
Validation Accuracy: [1 : 62.50000] [2 : 27.67857] [3 : nan] [4 : 36.60714] [5 : 26.78571] [6 : 40.17857] [7 : 25.89286] [8 : 64.28571] [9 : 44.64286]
validation loss: [1 : 0.76801] [2 : 2.08762] [3 : nan] [4 : 1.59592] [5 : 2.62349] [6 : 1.42495] [7 : 1.59476] [8 : 0.89185] [9 : 1.58357]
train loss: [1 : 0.75060] [2 : 1.35133] [3 : nan] [4 : 1.04529] [5 : 1.34700] [6 : 1.28379] [7 : 1.11958] [8 : 0.90105] [9 : 0.85782]
Epoch 7: 	validation acc: 41.07143	validation loss: 1.571272	train loss: 1.082059
Validation Accuracy: [1 : 58.92857] [2 : 29.46429] [3 : nan] [4 : 32.14286] [5 : 26.78571] [6 : 44.64286] [7 : 29.46429] [8 : 65.17857] [9 : 42.85714]
validation loss: [1 : 0.82527] [2 : 2.15735] [3 : nan] [4 : 1.53401] [5 : 2.71617] [6 : 1.49227] [7 : 1.56374] [8 : 0.84604] [9 : 1.61971]
train loss: [1 : 0.76984] [2 : 1.31309] [3 : nan] [4 : 1.03830] [5 : 1.33567] [6 : 1.22784] [7 : 1.07054] [8 : 0.89933] [9 : 0.86677]
Epoch 8: 	validation acc: 41.18304	validation loss: 1.594319	train loss: 1.065173
Validation Accuracy: [1 : 59.82143] [2 : 30.35714] [3 : nan] [4 : 36.60714] [5 : 25.00000] [6 : 39.28571] [7 : 31.25000] [8 : 69.64286] [9 : 47.32143]
validation loss: [1 : 0.80853] [2 : 1.99431] [3 : nan] [4 : 1.48225] [5 : 2.44935] [6 : 1.47491] [7 : 1.36320] [8 : 0.80716] [9 : 1.43263]
train loss: [1 : 0.75965] [2 : 1.27211] [3 : nan] [4 : 1.05990] [5 : 1.30928] [6 : 1.21320] [7 : 1.09385] [8 : 0.87014] [9 : 0.87401]
Epoch 9: 	validation acc: 42.41071	validation loss: 1.476541	train loss: 1.056517
Validation Accuracy: [1 : 58.92857] [2 : 27.67857] [3 : nan] [4 : 41.96429] [5 : 27.67857] [6 : 44.64286] [7 : 30.35714] [8 : 69.64286] [9 : 51.78571]
validation loss: [1 : 0.76567] [2 : 2.05269] [3 : nan] [4 : 1.44930] [5 : 2.69340] [6 : 1.50159] [7 : 1.57063] [8 : 0.78004] [9 : 1.43135]
train loss: [1 : 0.75833] [2 : 1.25904] [3 : nan] [4 : 1.04232] [5 : 1.33691] [6 : 1.16917] [7 : 1.04866] [8 : 0.84573] [9 : 0.85427]
Epoch 10: 	validation acc: 44.08482	validation loss: 1.530584	train loss: 1.039304
Validation Accuracy: [1 : 61.60714] [2 : 29.46429] [3 : nan] [4 : 41.07143] [5 : 27.67857] [6 : 46.42857] [7 : 31.25000] [8 : 68.75000] [9 : 49.10714]
validation loss: [1 : 0.76974] [2 : 2.06647] [3 : nan] [4 : 1.46011] [5 : 2.60964] [6 : 1.45246] [7 : 1.50031] [8 : 0.81052] [9 : 1.39930]
train loss: [1 : 0.74432] [2 : 1.26605] [3 : nan] [4 : 1.04653] [5 : 1.33270] [6 : 1.18595] [7 : 1.04260] [8 : 0.86244] [9 : 0.81262]
Epoch 11: 	validation acc: 44.41964	validation loss: 1.508569	train loss: 1.036652
Validation Accuracy: [1 : 61.60714] [2 : 32.14286] [3 : nan] [4 : 38.39286] [5 : 27.67857] [6 : 45.53571] [7 : 34.82143] [8 : 70.53571] [9 : 47.32143]
validation loss: [1 : 0.77246] [2 : 2.17454] [3 : nan] [4 : 1.61628] [5 : 2.76434] [6 : 1.51430] [7 : 1.46993] [8 : 0.79695] [9 : 1.45324]
train loss: [1 : 0.73640] [2 : 1.26661] [3 : nan] [4 : 1.00589] [5 : 1.29944] [6 : 1.17392] [7 : 1.02543] [8 : 0.80612] [9 : 0.83063]
Epoch 12: 	validation acc: 44.75446	validation loss: 1.570255	train loss: 1.018054
Validation Accuracy: [1 : 60.71429] [2 : 30.35714] [3 : nan] [4 : 47.32143] [5 : 26.78571] [6 : 42.85714] [7 : 39.28571] [8 : 69.64286] [9 : 50.00000]
validation loss: [1 : 0.80496] [2 : 2.09436] [3 : nan] [4 : 1.48540] [5 : 2.72687] [6 : 1.44397] [7 : 1.41669] [8 : 0.79358] [9 : 1.30616]
train loss: [1 : 0.68906] [2 : 1.21532] [3 : nan] [4 : 1.01575] [5 : 1.28401] [6 : 1.15961] [7 : 1.00463] [8 : 0.81628] [9 : 0.80592]
Epoch 13: 	validation acc: 45.87054	validation loss: 1.508998	train loss: 0.998822
Validation Accuracy: [1 : 58.92857] [2 : 29.46429] [3 : nan] [4 : 44.64286] [5 : 25.00000] [6 : 45.53571] [7 : 39.28571] [8 : 75.00000] [9 : 50.00000]
validation loss: [1 : 0.81047] [2 : 2.09147] [3 : nan] [4 : 1.48420] [5 : 2.60215] [6 : 1.33058] [7 : 1.39773] [8 : 0.77419] [9 : 1.41624]
train loss: [1 : 0.74178] [2 : 1.26641] [3 : nan] [4 : 0.97965] [5 : 1.25735] [6 : 1.15389] [7 : 0.99657] [8 : 0.84081] [9 : 0.84155]
Epoch 14: 	validation acc: 45.98214	validation loss: 1.488379	train loss: 1.009753
Validation Accuracy: [1 : 55.35714] [2 : 32.14286] [3 : nan] [4 : 42.85714] [5 : 25.89286] [6 : 50.89286] [7 : 41.07143] [8 : 71.42857] [9 : 52.67857]
validation loss: [1 : 0.82712] [2 : 2.13296] [3 : nan] [4 : 1.55288] [5 : 2.78353] [6 : 1.42480] [7 : 1.49133] [8 : 0.72165] [9 : 1.34492]
train loss: [1 : 0.69886] [2 : 1.22511] [3 : nan] [4 : 0.94791] [5 : 1.27379] [6 : 1.13249] [7 : 0.96599] [8 : 0.77970] [9 : 0.81064]
Epoch 15: 	validation acc: 46.54018	validation loss: 1.534899	train loss: 0.979313
Validation Accuracy: [1 : 61.60714] [2 : 33.92857] [3 : nan] [4 : 47.32143] [5 : 27.67857] [6 : 44.64286] [7 : 41.07143] [8 : 72.32143] [9 : 49.10714]
validation loss: [1 : 0.77682] [2 : 2.04220] [3 : nan] [4 : 1.43660] [5 : 2.78768] [6 : 1.40332] [7 : 1.36039] [8 : 0.77559] [9 : 1.36954]
train loss: [1 : 0.70055] [2 : 1.18660] [3 : nan] [4 : 0.95195] [5 : 1.23385] [6 : 1.16483] [7 : 0.96982] [8 : 0.78071] [9 : 0.83897]
Epoch 16: 	validation acc: 47.20982	validation loss: 1.494017	train loss: 0.978411
Validation Accuracy: [1 : 62.50000] [2 : 27.67857] [3 : nan] [4 : 46.42857] [5 : 26.78571] [6 : 50.00000] [7 : 37.50000] [8 : 70.53571] [9 : 52.67857]
validation loss: [1 : 0.76744] [2 : 2.18710] [3 : nan] [4 : 1.43334] [5 : 2.82744] [6 : 1.33188] [7 : 1.42629] [8 : 0.70602] [9 : 1.31297]
train loss: [1 : 0.71909] [2 : 1.26863] [3 : nan] [4 : 0.93814] [5 : 1.23919] [6 : 1.11787] [7 : 0.98254] [8 : 0.80814] [9 : 0.75091]
Epoch 17: 	validation acc: 46.76339	validation loss: 1.499058	train loss: 0.978063
Validation Accuracy: [1 : 65.17857] [2 : 30.35714] [3 : nan] [4 : 44.64286] [5 : 31.25000] [6 : 49.10714] [7 : 40.17857] [8 : 75.89286] [9 : 53.57143]
validation loss: [1 : 0.71870] [2 : 2.08361] [3 : nan] [4 : 1.39367] [5 : 2.53970] [6 : 1.47622] [7 : 1.35540] [8 : 0.71005] [9 : 1.17891]
train loss: [1 : 0.71372] [2 : 1.17456] [3 : nan] [4 : 0.93332] [5 : 1.27171] [6 : 1.12987] [7 : 0.93047] [8 : 0.78021] [9 : 0.81980]
Epoch 18: 	validation acc: 48.77232	validation loss: 1.432034	train loss: 0.969207
Validation Accuracy: [1 : 68.75000] [2 : 33.92857] [3 : nan] [4 : 49.10714] [5 : 28.57143] [6 : 49.10714] [7 : 42.85714] [8 : 72.32143] [9 : 53.57143]
validation loss: [1 : 0.74406] [2 : 2.26346] [3 : nan] [4 : 1.50062] [5 : 2.88547] [6 : 1.44368] [7 : 1.39303] [8 : 0.69235] [9 : 1.36379]
train loss: [1 : 0.66482] [2 : 1.17432] [3 : nan] [4 : 0.93794] [5 : 1.18402] [6 : 1.13044] [7 : 0.93914] [8 : 0.81765] [9 : 0.76259]
Epoch 19: 	validation acc: 49.77679	validation loss: 1.535806	train loss: 0.951366
Validation Accuracy: [1 : 62.50000] [2 : 29.46429] [3 : nan] [4 : 46.42857] [5 : 32.14286] [6 : 45.53571] [7 : 40.17857] [8 : 75.00000] [9 : 50.00000]
validation loss: [1 : 0.75253] [2 : 2.20052] [3 : nan] [4 : 1.47957] [5 : 2.67440] [6 : 1.48198] [7 : 1.40448] [8 : 0.70589] [9 : 1.40150]
train loss: [1 : 0.68006] [2 : 1.23056] [3 : nan] [4 : 0.96307] [5 : 1.20413] [6 : 1.09169] [7 : 0.91924] [8 : 0.77382] [9 : 0.77439]
Epoch 20: 	validation acc: 47.65625	validation loss: 1.512609	train loss: 0.954621
Validation Accuracy: [1 : 58.92857] [2 : 30.35714] [3 : nan] [4 : 46.42857] [5 : 26.78571] [6 : 46.42857] [7 : 44.64286] [8 : 69.64286] [9 : 50.00000]
validation loss: [1 : 0.74046] [2 : 2.25084] [3 : nan] [4 : 1.37277] [5 : 2.76567] [6 : 1.56417] [7 : 1.35221] [8 : 0.69771] [9 : 1.22785]
train loss: [1 : 0.70485] [2 : 1.18823] [3 : nan] [4 : 0.92782] [5 : 1.18803] [6 : 1.09261] [7 : 0.87854] [8 : 0.78634] [9 : 0.77033]
Epoch 21: 	validation acc: 46.65179	validation loss: 1.496461	train loss: 0.942094
Validation Accuracy: [1 : 64.28571] [2 : 31.25000] [3 : nan] [4 : 43.75000] [5 : 29.46429] [6 : 49.10714] [7 : 45.53571] [8 : 70.53571] [9 : 50.89286]
validation loss: [1 : 0.77659] [2 : 2.31016] [3 : nan] [4 : 1.50036] [5 : 2.79279] [6 : 1.49931] [7 : 1.33781] [8 : 0.70789] [9 : 1.22564]
train loss: [1 : 0.69442] [2 : 1.22275] [3 : nan] [4 : 0.92456] [5 : 1.23077] [6 : 1.11073] [7 : 0.91509] [8 : 0.79257] [9 : 0.78784]
Epoch 22: 	validation acc: 48.10268	validation loss: 1.518819	train loss: 0.959840
Validation Accuracy: [1 : 66.96429] [2 : 31.25000] [3 : nan] [4 : 45.53571] [5 : 27.67857] [6 : 50.89286] [7 : 42.85714] [8 : 71.42857] [9 : 51.78571]
validation loss: [1 : 0.75849] [2 : 2.25695] [3 : nan] [4 : 1.44893] [5 : 2.73539] [6 : 1.52140] [7 : 1.38245] [8 : 0.69321] [9 : 1.16577]
train loss: [1 : 0.68268] [2 : 1.16991] [3 : nan] [4 : 0.92244] [5 : 1.21714] [6 : 1.07689] [7 : 0.88017] [8 : 0.76350] [9 : 0.78777]
Epoch 23: 	validation acc: 48.54911	validation loss: 1.495322	train loss: 0.937562
Validation Accuracy: [1 : 64.28571] [2 : 30.35714] [3 : nan] [4 : 47.32143] [5 : 31.25000] [6 : 50.00000] [7 : 46.42857] [8 : 66.96429] [9 : 55.35714]
validation loss: [1 : 0.76621] [2 : 2.15084] [3 : nan] [4 : 1.42353] [5 : 2.70535] [6 : 1.37991] [7 : 1.31937] [8 : 0.69908] [9 : 1.18946]
train loss: [1 : 0.68200] [2 : 1.19498] [3 : nan] [4 : 0.88536] [5 : 1.23550] [6 : 1.09290] [7 : 0.89486] [8 : 0.79045] [9 : 0.75282]
Epoch 24: 	validation acc: 48.99554	validation loss: 1.454220	train loss: 0.941110
Validation Accuracy: [1 : 63.39286] [2 : 34.82143] [3 : nan] [4 : 45.53571] [5 : 28.57143] [6 : 48.21429] [7 : 41.96429] [8 : 68.75000] [9 : 58.03571]
validation loss: [1 : 0.74999] [2 : 2.10981] [3 : nan] [4 : 1.40381] [5 : 2.77074] [6 : 1.46254] [7 : 1.34130] [8 : 0.72461] [9 : 1.17357]
train loss: [1 : 0.69292] [2 : 1.22677] [3 : nan] [4 : 0.87623] [5 : 1.20216] [6 : 1.12250] [7 : 0.89557] [8 : 0.75147] [9 : 0.77841]
Epoch 25: 	validation acc: 48.66071	validation loss: 1.467048	train loss: 0.943253
Validation Accuracy: [1 : 64.28571] [2 : 33.03571] [3 : nan] [4 : 45.53571] [5 : 30.35714] [6 : 47.32143] [7 : 41.07143] [8 : 66.96429] [9 : 58.92857]
validation loss: [1 : 0.76523] [2 : 2.27191] [3 : nan] [4 : 1.55939] [5 : 2.82540] [6 : 1.62585] [7 : 1.36135] [8 : 0.76538] [9 : 1.06375]
train loss: [1 : 0.67654] [2 : 1.16229] [3 : nan] [4 : 0.87385] [5 : 1.23207] [6 : 1.05950] [7 : 0.85809] [8 : 0.78535] [9 : 0.74375]
Epoch 26: 	validation acc: 48.43750	validation loss: 1.529785	train loss: 0.923929
Validation Accuracy: [1 : 68.75000] [2 : 29.46429] [3 : nan] [4 : 44.64286] [5 : 29.46429] [6 : 50.00000] [7 : 42.85714] [8 : 71.42857] [9 : 54.46429]
validation loss: [1 : 0.75436] [2 : 2.21095] [3 : nan] [4 : 1.49449] [5 : 2.76281] [6 : 1.57859] [7 : 1.32795] [8 : 0.70614] [9 : 1.19917]
train loss: [1 : 0.66385] [2 : 1.14593] [3 : nan] [4 : 0.91096] [5 : 1.20669] [6 : 1.08877] [7 : 0.89264] [8 : 0.76161] [9 : 0.74138]
Epoch 27: 	validation acc: 48.88393	validation loss: 1.504307	train loss: 0.926478
Validation Accuracy: [1 : 74.10714] [2 : 33.92857] [3 : nan] [4 : 48.21429] [5 : 30.35714] [6 : 49.10714] [7 : 43.75000] [8 : 73.21429] [9 : 50.89286]
validation loss: [1 : 0.67451] [2 : 2.22544] [3 : nan] [4 : 1.45005] [5 : 2.65859] [6 : 1.57704] [7 : 1.35179] [8 : 0.67073] [9 : 1.25059]
train loss: [1 : 0.67569] [2 : 1.14954] [3 : nan] [4 : 0.88676] [5 : 1.16108] [6 : 1.06731] [7 : 0.86100] [8 : 0.77853] [9 : 0.75450]
Epoch 28: 	validation acc: 50.44643	validation loss: 1.482341	train loss: 0.916802
Validation Accuracy: [1 : 61.60714] [2 : 28.57143] [3 : nan] [4 : 41.96429] [5 : 27.67857] [6 : 48.21429] [7 : 40.17857] [8 : 73.21429] [9 : 56.25000]
validation loss: [1 : 0.74893] [2 : 2.20764] [3 : nan] [4 : 1.49971] [5 : 2.72056] [6 : 1.47064] [7 : 1.44126] [8 : 0.67529] [9 : 1.16020]
train loss: [1 : 0.64891] [2 : 1.18514] [3 : nan] [4 : 0.96163] [5 : 1.18886] [6 : 1.08210] [7 : 0.86575] [8 : 0.74559] [9 : 0.75616]
Epoch 29: 	validation acc: 47.20982	validation loss: 1.490527	train loss: 0.929269
Validation Accuracy: [1 : 64.28571] [2 : 32.14286] [3 : nan] [4 : 45.53571] [5 : 28.57143] [6 : 49.10714] [7 : 42.85714] [8 : 71.42857] [9 : 59.82143]
validation loss: [1 : 0.78187] [2 : 2.17190] [3 : nan] [4 : 1.41933] [5 : 2.76446] [6 : 1.50589] [7 : 1.31794] [8 : 0.70360] [9 : 1.25647]
train loss: [1 : 0.66006] [2 : 1.17420] [3 : nan] [4 : 0.87771] [5 : 1.16032] [6 : 1.11594] [7 : 0.85531] [8 : 0.70871] [9 : 0.77106]
Epoch 30: 	validation acc: 49.21875	validation loss: 1.490183	train loss: 0.915413
Validation Accuracy: [1 : 67.85714] [2 : 29.46429] [3 : nan] [4 : 45.53571] [5 : 27.67857] [6 : 46.42857] [7 : 41.07143] [8 : 70.53571] [9 : 58.92857]
validation loss: [1 : 0.75527] [2 : 2.21102] [3 : nan] [4 : 1.50304] [5 : 2.75080] [6 : 1.50135] [7 : 1.27660] [8 : 0.69581] [9 : 1.10629]
train loss: [1 : 0.68279] [2 : 1.21887] [3 : nan] [4 : 0.82886] [5 : 1.21800] [6 : 1.08179] [7 : 0.89183] [8 : 0.71426] [9 : 0.74144]
Epoch 31: 	validation acc: 48.43750	validation loss: 1.475023	train loss: 0.922230
Validation Accuracy: [1 : 64.28571] [2 : 36.60714] [3 : nan] [4 : 42.85714] [5 : 30.35714] [6 : 46.42857] [7 : 41.07143] [8 : 70.53571] [9 : 56.25000]
validation loss: [1 : 0.74696] [2 : 2.23437] [3 : nan] [4 : 1.52851] [5 : 2.69502] [6 : 1.63793] [7 : 1.31096] [8 : 0.76212] [9 : 1.19128]
train loss: [1 : 0.65851] [2 : 1.15453] [3 : nan] [4 : 0.87499] [5 : 1.14669] [6 : 1.10254] [7 : 0.80124] [8 : 0.72009] [9 : 0.78390]
Epoch 32: 	validation acc: 48.54911	validation loss: 1.513394	train loss: 0.905310
Validation Accuracy: [1 : 61.60714] [2 : 33.03571] [3 : nan] [4 : 46.42857] [5 : 33.03571] [6 : 47.32143] [7 : 44.64286] [8 : 69.64286] [9 : 60.71429]
validation loss: [1 : 0.77828] [2 : 2.13682] [3 : nan] [4 : 1.44501] [5 : 2.62846] [6 : 1.48807] [7 : 1.29801] [8 : 0.72806] [9 : 1.14120]
train loss: [1 : 0.68043] [2 : 1.20069] [3 : nan] [4 : 0.83886] [5 : 1.09484] [6 : 1.07920] [7 : 0.82163] [8 : 0.77371] [9 : 0.77087]
Epoch 33: 	validation acc: 49.55357	validation loss: 1.455488	train loss: 0.907529
Validation Accuracy: [1 : 62.50000] [2 : 33.03571] [3 : nan] [4 : 49.10714] [5 : 29.46429] [6 : 46.42857] [7 : 43.75000] [8 : 68.75000] [9 : 59.82143]
validation loss: [1 : 0.79156] [2 : 2.11582] [3 : nan] [4 : 1.39210] [5 : 2.66242] [6 : 1.56625] [7 : 1.30569] [8 : 0.71701] [9 : 1.06810]
train loss: [1 : 0.65570] [2 : 1.15570] [3 : nan] [4 : 0.88268] [5 : 1.13271] [6 : 1.07428] [7 : 0.84716] [8 : 0.75442] [9 : 0.72894]
Epoch 34: 	validation acc: 49.10714	validation loss: 1.452369	train loss: 0.903949
Validation Accuracy: [1 : 67.85714] [2 : 31.25000] [3 : nan] [4 : 45.53571] [5 : 27.67857] [6 : 48.21429] [7 : 41.96429] [8 : 74.10714] [9 : 53.57143]
validation loss: [1 : 0.72909] [2 : 2.20392] [3 : nan] [4 : 1.41205] [5 : 2.81216] [6 : 1.59650] [7 : 1.34291] [8 : 0.66459] [9 : 1.19873]
train loss: [1 : 0.65126] [2 : 1.17719] [3 : nan] [4 : 0.86161] [5 : 1.16596] [6 : 1.07225] [7 : 0.80836] [8 : 0.71370] [9 : 0.75388]
Epoch 35: 	validation acc: 48.77232	validation loss: 1.494992	train loss: 0.900527
Validation Accuracy: [1 : 69.64286] [2 : 36.60714] [3 : nan] [4 : 45.53571] [5 : 33.92857] [6 : 45.53571] [7 : 43.75000] [8 : 73.21429] [9 : 56.25000]
validation loss: [1 : 0.71114] [2 : 2.23305] [3 : nan] [4 : 1.48010] [5 : 2.72241] [6 : 1.51916] [7 : 1.34776] [8 : 0.68642] [9 : 1.11574]
train loss: [1 : 0.63924] [2 : 1.14302] [3 : nan] [4 : 0.89556] [5 : 1.09138] [6 : 1.03554] [7 : 0.84320] [8 : 0.76402] [9 : 0.75286]
Epoch 36: 	validation acc: 50.55804	validation loss: 1.476973	train loss: 0.895604
Validation Accuracy: [1 : 65.17857] [2 : 37.50000] [3 : nan] [4 : 45.53571] [5 : 31.25000] [6 : 47.32143] [7 : 47.32143] [8 : 72.32143] [9 : 58.03571]
validation loss: [1 : 0.73730] [2 : 2.13033] [3 : nan] [4 : 1.43274] [5 : 2.66061] [6 : 1.47086] [7 : 1.27423] [8 : 0.72899] [9 : 1.16311]
train loss: [1 : 0.66415] [2 : 1.16325] [3 : nan] [4 : 0.85825] [5 : 1.16176] [6 : 1.08982] [7 : 0.83344] [8 : 0.71812] [9 : 0.76770]
Epoch 37: 	validation acc: 50.55804	validation loss: 1.449771	train loss: 0.907062
Validation Accuracy: [1 : 66.07143] [2 : 33.03571] [3 : nan] [4 : 42.85714] [5 : 27.67857] [6 : 49.10714] [7 : 44.64286] [8 : 71.42857] [9 : 58.92857]
validation loss: [1 : 0.76520] [2 : 2.21631] [3 : nan] [4 : 1.48159] [5 : 2.79225] [6 : 1.48773] [7 : 1.31787] [8 : 0.66339] [9 : 1.08721]
train loss: [1 : 0.60065] [2 : 1.18128] [3 : nan] [4 : 0.85690] [5 : 1.11370] [6 : 1.04747] [7 : 0.81065] [8 : 0.72578] [9 : 0.71002]
Epoch 38: 	validation acc: 49.21875	validation loss: 1.476444	train loss: 0.880807
Validation Accuracy: [1 : 66.96429] [2 : 32.14286] [3 : nan] [4 : 49.10714] [5 : 30.35714] [6 : 52.67857] [7 : 43.75000] [8 : 69.64286] [9 : 59.82143]
validation loss: [1 : 0.73477] [2 : 2.14766] [3 : nan] [4 : 1.47768] [5 : 2.64633] [6 : 1.44340] [7 : 1.27143] [8 : 0.69814] [9 : 1.05989]
train loss: [1 : 0.68512] [2 : 1.12182] [3 : nan] [4 : 0.82899] [5 : 1.09921] [6 : 1.00893] [7 : 0.78287] [8 : 0.71472] [9 : 0.75293]
Epoch 39: 	validation acc: 50.55804	validation loss: 1.434912	train loss: 0.874323
Validation Accuracy: [1 : 67.85714] [2 : 34.82143] [3 : nan] [4 : 47.32143] [5 : 29.46429] [6 : 48.21429] [7 : 41.07143] [8 : 69.64286] [9 : 62.50000]
validation loss: [1 : 0.73647] [2 : 2.12966] [3 : nan] [4 : 1.40388] [5 : 2.75037] [6 : 1.64272] [7 : 1.32571] [8 : 0.68346] [9 : 1.02909]
train loss: [1 : 0.66131] [2 : 1.19621] [3 : nan] [4 : 0.83052] [5 : 1.10704] [6 : 1.05201] [7 : 0.82464] [8 : 0.74630] [9 : 0.75143]
Epoch 40: 	validation acc: 50.11161	validation loss: 1.462668	train loss: 0.896184
Validation Accuracy: [1 : 62.50000] [2 : 34.82143] [3 : nan] [4 : 48.21429] [5 : 26.78571] [6 : 50.89286] [7 : 46.42857] [8 : 72.32143] [9 : 60.71429]
validation loss: [1 : 0.78847] [2 : 2.19457] [3 : nan] [4 : 1.31210] [5 : 2.67742] [6 : 1.52482] [7 : 1.27280] [8 : 0.67807] [9 : 1.03953]
train loss: [1 : 0.68347] [2 : 1.19459] [3 : nan] [4 : 0.91050] [5 : 1.14148] [6 : 1.04164] [7 : 0.80675] [8 : 0.71115] [9 : 0.73809]
Epoch 41: 	validation acc: 50.33482	validation loss: 1.435972	train loss: 0.903460
Validation Accuracy: [1 : 65.17857] [2 : 27.67857] [3 : nan] [4 : 44.64286] [5 : 30.35714] [6 : 51.78571] [7 : 47.32143] [8 : 72.32143] [9 : 60.71429]
validation loss: [1 : 0.72226] [2 : 2.18693] [3 : nan] [4 : 1.50097] [5 : 2.84531] [6 : 1.62671] [7 : 1.23535] [8 : 0.69087] [9 : 1.10515]
train loss: [1 : 0.67490] [2 : 1.12161] [3 : nan] [4 : 0.89832] [5 : 1.12333] [6 : 1.08166] [7 : 0.79499] [8 : 0.73117] [9 : 0.72442]
Epoch 42: 	validation acc: 50.00000	validation loss: 1.489193	train loss: 0.893801
Validation Accuracy: [1 : 68.75000] [2 : 33.03571] [3 : nan] [4 : 49.10714] [5 : 29.46429] [6 : 49.10714] [7 : 45.53571] [8 : 71.42857] [9 : 55.35714]
validation loss: [1 : 0.74553] [2 : 2.13965] [3 : nan] [4 : 1.39715] [5 : 2.75385] [6 : 1.50806] [7 : 1.28752] [8 : 0.66955] [9 : 0.99120]
train loss: [1 : 0.63516] [2 : 1.15179] [3 : nan] [4 : 0.88853] [5 : 1.11265] [6 : 1.09351] [7 : 0.78139] [8 : 0.69009] [9 : 0.72562]
Epoch 43: 	validation acc: 50.22321	validation loss: 1.436565	train loss: 0.884842
Validation Accuracy: [1 : 66.07143] [2 : 31.25000] [3 : nan] [4 : 44.64286] [5 : 29.46429] [6 : 50.89286] [7 : 49.10714] [8 : 67.85714] [9 : 58.92857]
validation loss: [1 : 0.76538] [2 : 2.35503] [3 : nan] [4 : 1.44404] [5 : 2.97876] [6 : 1.47248] [7 : 1.33727] [8 : 0.68347] [9 : 1.11566]
train loss: [1 : 0.64070] [2 : 1.05889] [3 : nan] [4 : 0.83620] [5 : 1.13076] [6 : 1.04856] [7 : 0.79802] [8 : 0.70975] [9 : 0.73068]
Epoch 44: 	validation acc: 49.77679	validation loss: 1.519012	train loss: 0.869195
Validation Accuracy: [1 : 62.50000] [2 : 33.92857] [3 : nan] [4 : 49.10714] [5 : 31.25000] [6 : 49.10714] [7 : 41.07143] [8 : 70.53571] [9 : 58.92857]
validation loss: [1 : 0.72755] [2 : 2.22096] [3 : nan] [4 : 1.42271] [5 : 2.70719] [6 : 1.55975] [7 : 1.32895] [8 : 0.71420] [9 : 1.07566]
train loss: [1 : 0.66350] [2 : 1.14527] [3 : nan] [4 : 0.84102] [5 : 1.13307] [6 : 1.06704] [7 : 0.76529] [8 : 0.74995] [9 : 0.69347]
Epoch 45: 	validation acc: 49.55357	validation loss: 1.469620	train loss: 0.882326
Validation Accuracy: [1 : 66.96429] [2 : 33.92857] [3 : nan] [4 : 45.53571] [5 : 30.35714] [6 : 49.10714] [7 : 45.53571] [8 : 70.53571] [9 : 60.71429]
validation loss: [1 : 0.76077] [2 : 2.19713] [3 : nan] [4 : 1.36016] [5 : 2.86187] [6 : 1.60459] [7 : 1.31111] [8 : 0.68479] [9 : 1.01868]
train loss: [1 : 0.65641] [2 : 1.14285] [3 : nan] [4 : 0.84034] [5 : 1.06146] [6 : 1.04860] [7 : 0.75595] [8 : 0.70445] [9 : 0.72723]
Epoch 46: 	validation acc: 50.33482	validation loss: 1.474887	train loss: 0.867161
Validation Accuracy: [1 : 66.96429] [2 : 32.14286] [3 : nan] [4 : 49.10714] [5 : 31.25000] [6 : 50.00000] [7 : 41.96429] [8 : 69.64286] [9 : 62.50000]
validation loss: [1 : 0.73430] [2 : 2.32249] [3 : nan] [4 : 1.47316] [5 : 2.87221] [6 : 1.47768] [7 : 1.36746] [8 : 0.70724] [9 : 1.05599]
train loss: [1 : 0.65444] [2 : 1.19944] [3 : nan] [4 : 0.87373] [5 : 1.10354] [6 : 1.03344] [7 : 0.76516] [8 : 0.68650] [9 : 0.70184]
Epoch 47: 	validation acc: 50.44643	validation loss: 1.501316	train loss: 0.877262
Validation Accuracy: [1 : 64.28571] [2 : 33.92857] [3 : nan] [4 : 50.00000] [5 : 30.35714] [6 : 50.00000] [7 : 41.96429] [8 : 69.64286] [9 : 56.25000]
validation loss: [1 : 0.74073] [2 : 2.26301] [3 : nan] [4 : 1.46359] [5 : 2.83802] [6 : 1.60237] [7 : 1.34456] [8 : 0.71148] [9 : 1.08109]
train loss: [1 : 0.61672] [2 : 1.14885] [3 : nan] [4 : 0.87649] [5 : 1.06744] [6 : 1.01430] [7 : 0.80849] [8 : 0.67706] [9 : 0.74217]
Epoch 48: 	validation acc: 49.55357	validation loss: 1.505606	train loss: 0.868939
Validation Accuracy: [1 : 66.07143] [2 : 33.03571] [3 : nan] [4 : 50.00000] [5 : 32.14286] [6 : 48.21429] [7 : 43.75000] [8 : 69.64286] [9 : 58.03571]
validation loss: [1 : 0.74719] [2 : 2.29421] [3 : nan] [4 : 1.46932] [5 : 2.83308] [6 : 1.53343] [7 : 1.29704] [8 : 0.65851] [9 : 1.12625]
train loss: [1 : 0.65786] [2 : 1.12916] [3 : nan] [4 : 0.87254] [5 : 1.10225] [6 : 1.05106] [7 : 0.76248] [8 : 0.69284] [9 : 0.73343]
Epoch 49: 	validation acc: 50.11161	validation loss: 1.494879	train loss: 0.875204

Evaluate on train subjects:
0-shot accuracy on subject 1: 	mean: 73.263889%	std: 12.724640%
0-shot accuracy on subject 2: 	mean: 53.125000%	std: 12.968645%
0-shot accuracy on subject 4: 	mean: 65.277778%	std: 12.276159%
0-shot accuracy on subject 5: 	mean: 50.347222%	std: 13.971111%
0-shot accuracy on subject 6: 	mean: 56.076389%	std: 12.367888%
0-shot accuracy on subject 7: 	mean: 69.791667%	std: 12.103073%
0-shot accuracy on subject 8: 	mean: 74.131944%	std: 9.099276%
0-shot accuracy on subject 9: 	mean: 70.486111%	std: 9.948992%
Validation Accuracy: [1 : nan] [2 : nan] [3 : 75.89286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.63801] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.76909] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 1: 	validation acc: 75.89286	validation loss: 0.638007	train loss: 0.769087
Validation Accuracy: [1 : nan] [2 : nan] [3 : 76.78571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.57385] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.67374] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 2: 	validation acc: 76.78571	validation loss: 0.573853	train loss: 0.673739
Validation Accuracy: [1 : nan] [2 : nan] [3 : 79.46429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.53782] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.60116] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 3: 	validation acc: 79.46429	validation loss: 0.537819	train loss: 0.601161
Validation Accuracy: [1 : nan] [2 : nan] [3 : 79.46429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.50478] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.58516] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 4: 	validation acc: 79.46429	validation loss: 0.504781	train loss: 0.585163
Validation Accuracy: [1 : nan] [2 : nan] [3 : 79.46429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.48131] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.56361] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 5: 	validation acc: 79.46429	validation loss: 0.481310	train loss: 0.563607
Validation Accuracy: [1 : nan] [2 : nan] [3 : 83.03571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.47107] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.53273] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 6: 	validation acc: 83.03571	validation loss: 0.471071	train loss: 0.532729
Validation Accuracy: [1 : nan] [2 : nan] [3 : 83.03571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.45594] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.52844] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 7: 	validation acc: 83.03571	validation loss: 0.455939	train loss: 0.528439
Validation Accuracy: [1 : nan] [2 : nan] [3 : 82.14286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.43249] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.49074] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 8: 	validation acc: 82.14286	validation loss: 0.432487	train loss: 0.490737
Validation Accuracy: [1 : nan] [2 : nan] [3 : 85.71429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.42335] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.43776] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 9: 	validation acc: 85.71429	validation loss: 0.423352	train loss: 0.437763
Validation Accuracy: [1 : nan] [2 : nan] [3 : 85.71429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.41524] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.43491] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 10: 	validation acc: 85.71429	validation loss: 0.415243	train loss: 0.434910
Validation Accuracy: [1 : nan] [2 : nan] [3 : 85.71429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.40431] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.42842] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 11: 	validation acc: 85.71429	validation loss: 0.404314	train loss: 0.428425
Validation Accuracy: [1 : nan] [2 : nan] [3 : 85.71429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.39504] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.42199] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 12: 	validation acc: 85.71429	validation loss: 0.395040	train loss: 0.421988
Validation Accuracy: [1 : nan] [2 : nan] [3 : 83.92857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.38016] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.39924] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 13: 	validation acc: 83.92857	validation loss: 0.380159	train loss: 0.399238
Validation Accuracy: [1 : nan] [2 : nan] [3 : 85.71429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.38324] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.39629] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 14: 	validation acc: 85.71429	validation loss: 0.383239	train loss: 0.396292
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.39499] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.37283] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 15: 	validation acc: 87.50000	validation loss: 0.394990	train loss: 0.372835
Validation Accuracy: [1 : nan] [2 : nan] [3 : 85.71429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.38231] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.35510] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 16: 	validation acc: 85.71429	validation loss: 0.382312	train loss: 0.355097
Validation Accuracy: [1 : nan] [2 : nan] [3 : 84.82143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.36932] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.34046] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 17: 	validation acc: 84.82143	validation loss: 0.369321	train loss: 0.340456
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.36474] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.34119] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 18: 	validation acc: 87.50000	validation loss: 0.364745	train loss: 0.341190
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.37010] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.32441] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 19: 	validation acc: 89.28571	validation loss: 0.370098	train loss: 0.324412
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.37486] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.29993] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 20: 	validation acc: 88.39286	validation loss: 0.374860	train loss: 0.299928
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.36412] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.32948] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 21: 	validation acc: 87.50000	validation loss: 0.364121	train loss: 0.329475
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.34997] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.32609] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 22: 	validation acc: 88.39286	validation loss: 0.349968	train loss: 0.326086
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.33703] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.30293] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 23: 	validation acc: 88.39286	validation loss: 0.337034	train loss: 0.302931
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.33504] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.27232] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 24: 	validation acc: 89.28571	validation loss: 0.335037	train loss: 0.272324
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.35460] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.25785] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 25: 	validation acc: 87.50000	validation loss: 0.354601	train loss: 0.257849
Validation Accuracy: [1 : nan] [2 : nan] [3 : 85.71429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.35269] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.23450] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 26: 	validation acc: 85.71429	validation loss: 0.352693	train loss: 0.234504
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.34607] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.26596] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 27: 	validation acc: 88.39286	validation loss: 0.346067	train loss: 0.265959
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32955] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.25770] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 28: 	validation acc: 88.39286	validation loss: 0.329546	train loss: 0.257705
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.31953] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.21965] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 29: 	validation acc: 88.39286	validation loss: 0.319531	train loss: 0.219655
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.31798] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.22738] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 30: 	validation acc: 87.50000	validation loss: 0.317976	train loss: 0.227376
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.31680] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.26755] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 31: 	validation acc: 88.39286	validation loss: 0.316798	train loss: 0.267554
Validation Accuracy: [1 : nan] [2 : nan] [3 : 86.60714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.33907] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.23387] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 32: 	validation acc: 86.60714	validation loss: 0.339073	train loss: 0.233872
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.33031] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.23303] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 33: 	validation acc: 89.28571	validation loss: 0.330311	train loss: 0.233032
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32452] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.19496] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 34: 	validation acc: 90.17857	validation loss: 0.324518	train loss: 0.194958
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32460] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.26195] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 35: 	validation acc: 89.28571	validation loss: 0.324596	train loss: 0.261947
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29928] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.19349] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 36: 	validation acc: 90.17857	validation loss: 0.299275	train loss: 0.193493
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.30153] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.20888] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 37: 	validation acc: 89.28571	validation loss: 0.301528	train loss: 0.208878
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.31405] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.20956] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 38: 	validation acc: 88.39286	validation loss: 0.314050	train loss: 0.209564
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32112] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.20992] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 39: 	validation acc: 87.50000	validation loss: 0.321118	train loss: 0.209924
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32164] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.19088] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 40: 	validation acc: 87.50000	validation loss: 0.321642	train loss: 0.190885
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.31777] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.15837] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 41: 	validation acc: 87.50000	validation loss: 0.317768	train loss: 0.158367
Validation Accuracy: [1 : nan] [2 : nan] [3 : 86.60714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32942] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.20503] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 42: 	validation acc: 86.60714	validation loss: 0.329425	train loss: 0.205025
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32990] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.19238] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 43: 	validation acc: 87.50000	validation loss: 0.329899	train loss: 0.192383
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32017] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.15911] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 44: 	validation acc: 87.50000	validation loss: 0.320171	train loss: 0.159110
Validation Accuracy: [1 : nan] [2 : nan] [3 : 86.60714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.31520] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.18124] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 45: 	validation acc: 86.60714	validation loss: 0.315198	train loss: 0.181243
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.30992] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.17831] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 46: 	validation acc: 87.50000	validation loss: 0.309916	train loss: 0.178309
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28755] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.15402] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 47: 	validation acc: 88.39286	validation loss: 0.287548	train loss: 0.154018
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29464] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.17171] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 48: 	validation acc: 89.28571	validation loss: 0.294638	train loss: 0.171711
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32810] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.17336] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 49: 	validation acc: 87.50000	validation loss: 0.328099	train loss: 0.173356
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.33019] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.15882] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 50: 	validation acc: 87.50000	validation loss: 0.330193	train loss: 0.158819
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.31796] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.15679] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 51: 	validation acc: 89.28571	validation loss: 0.317965	train loss: 0.156785
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29521] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.17364] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 52: 	validation acc: 89.28571	validation loss: 0.295209	train loss: 0.173642
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.30917] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.12726] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 53: 	validation acc: 89.28571	validation loss: 0.309166	train loss: 0.127258
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29519] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.13866] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 54: 	validation acc: 89.28571	validation loss: 0.295189	train loss: 0.138659
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28723] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14880] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 55: 	validation acc: 88.39286	validation loss: 0.287225	train loss: 0.148800
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28602] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14476] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 56: 	validation acc: 90.17857	validation loss: 0.286022	train loss: 0.144757
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.30552] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14182] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 57: 	validation acc: 87.50000	validation loss: 0.305524	train loss: 0.141819
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.31857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.16375] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 58: 	validation acc: 88.39286	validation loss: 0.318573	train loss: 0.163747
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29767] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.16469] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 59: 	validation acc: 90.17857	validation loss: 0.297671	train loss: 0.164688
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27924] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14659] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 60: 	validation acc: 89.28571	validation loss: 0.279236	train loss: 0.146585
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28870] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14175] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 61: 	validation acc: 88.39286	validation loss: 0.288699	train loss: 0.141747
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.30237] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.18308] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 62: 	validation acc: 89.28571	validation loss: 0.302374	train loss: 0.183085
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.07143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27302] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.15331] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 63: 	validation acc: 91.07143	validation loss: 0.273025	train loss: 0.153308
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.25250] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.13647] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 64: 	validation acc: 88.39286	validation loss: 0.252503	train loss: 0.136466
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26403] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.15789] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 65: 	validation acc: 88.39286	validation loss: 0.264032	train loss: 0.157887
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.07143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28256] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10097] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 66: 	validation acc: 91.07143	validation loss: 0.282563	train loss: 0.100975
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27848] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.12978] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 67: 	validation acc: 90.17857	validation loss: 0.278476	train loss: 0.129780
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28086] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.16984] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 68: 	validation acc: 87.50000	validation loss: 0.280865	train loss: 0.169844
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26930] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.13269] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 69: 	validation acc: 89.28571	validation loss: 0.269298	train loss: 0.132686
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29975] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14702] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 70: 	validation acc: 88.39286	validation loss: 0.299747	train loss: 0.147016
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28806] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14064] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 71: 	validation acc: 90.17857	validation loss: 0.288061	train loss: 0.140644
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28169] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.15526] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 72: 	validation acc: 90.17857	validation loss: 0.281689	train loss: 0.155260
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26777] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.11757] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 73: 	validation acc: 89.28571	validation loss: 0.267774	train loss: 0.117568
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26607] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.11516] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 74: 	validation acc: 89.28571	validation loss: 0.266069	train loss: 0.115163
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26664] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.15797] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 75: 	validation acc: 89.28571	validation loss: 0.266638	train loss: 0.157971
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26431] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14033] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 76: 	validation acc: 89.28571	validation loss: 0.264309	train loss: 0.140326
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27236] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.13827] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 77: 	validation acc: 89.28571	validation loss: 0.272356	train loss: 0.138271
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28261] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14377] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 78: 	validation acc: 89.28571	validation loss: 0.282607	train loss: 0.143765
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28831] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.12180] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 79: 	validation acc: 89.28571	validation loss: 0.288312	train loss: 0.121803
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28023] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14193] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 80: 	validation acc: 89.28571	validation loss: 0.280230	train loss: 0.141934
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27740] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09108] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 81: 	validation acc: 90.17857	validation loss: 0.277402	train loss: 0.091076
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29175] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.12215] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 82: 	validation acc: 90.17857	validation loss: 0.291748	train loss: 0.122150
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29234] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09506] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 83: 	validation acc: 89.28571	validation loss: 0.292345	train loss: 0.095059
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28658] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.12080] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 84: 	validation acc: 89.28571	validation loss: 0.286584	train loss: 0.120801
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.07143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28489] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08925] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 85: 	validation acc: 91.07143	validation loss: 0.284885	train loss: 0.089255
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27999] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.13075] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 86: 	validation acc: 90.17857	validation loss: 0.279987	train loss: 0.130748
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27041] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.12645] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 87: 	validation acc: 87.50000	validation loss: 0.270411	train loss: 0.126455
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.25180] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10163] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 88: 	validation acc: 88.39286	validation loss: 0.251802	train loss: 0.101632
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.07143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26011] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10739] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 89: 	validation acc: 91.07143	validation loss: 0.260112	train loss: 0.107386
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27993] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09073] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 90: 	validation acc: 89.28571	validation loss: 0.279929	train loss: 0.090730
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26645] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09587] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 91: 	validation acc: 90.17857	validation loss: 0.266446	train loss: 0.095875
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.96429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27739] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10677] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 92: 	validation acc: 91.96429	validation loss: 0.277392	train loss: 0.106773
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28908] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09120] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 93: 	validation acc: 90.17857	validation loss: 0.289081	train loss: 0.091200
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28879] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.11247] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 94: 	validation acc: 90.17857	validation loss: 0.288792	train loss: 0.112470
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.07143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26250] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09548] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 95: 	validation acc: 91.07143	validation loss: 0.262498	train loss: 0.095483
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.07143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.25578] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08887] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 96: 	validation acc: 91.07143	validation loss: 0.255784	train loss: 0.088872
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27946] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.13420] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 97: 	validation acc: 89.28571	validation loss: 0.279458	train loss: 0.134197
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.28876] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09605] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 98: 	validation acc: 88.39286	validation loss: 0.288762	train loss: 0.096048
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29458] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07626] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 99: 	validation acc: 88.39286	validation loss: 0.294581	train loss: 0.076257
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29568] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10147] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 100: 	validation acc: 89.28571	validation loss: 0.295677	train loss: 0.101470

Reptile
episode: 0	finetune acc: 18.75000		test acc: 33.33333
episode: 50	finetune acc: 48.75000		test acc: 35.41667
episode: 100	finetune acc: 36.25000		test acc: 47.91667
episode: 150	finetune acc: 38.75000		test acc: 52.08333
episode: 200	finetune acc: 51.25000		test acc: 47.91667
episode: 250	finetune acc: 46.25000		test acc: 54.16667
episode: 300	finetune acc: 42.50000		test acc: 56.25000
episode: 350	finetune acc: 57.50000		test acc: 64.58333
episode: 400	finetune acc: 56.25000		test acc: 43.75000
episode: 450	finetune acc: 50.00000		test acc: 58.33333
episode: 500	finetune acc: 60.00000		test acc: 58.33333
episode: 550	finetune acc: 47.50000		test acc: 58.33333
episode: 600	finetune acc: 45.00000		test acc: 64.58333
episode: 650	finetune acc: 51.25000		test acc: 60.41667
episode: 700	finetune acc: 50.00000		test acc: 62.50000
episode: 750	finetune acc: 47.50000		test acc: 72.91667
episode: 800	finetune acc: 55.00000		test acc: 64.58333
episode: 850	finetune acc: 50.00000		test acc: 70.83333
episode: 900	finetune acc: 51.25000		test acc: 60.41667
episode: 950	finetune acc: 46.25000		test acc: 77.08333
episode: 1000	finetune acc: 48.75000		test acc: 66.66667
episode: 1050	finetune acc: 58.75000		test acc: 68.75000
episode: 1100	finetune acc: 56.25000		test acc: 56.25000
episode: 1150	finetune acc: 65.00000		test acc: 64.58333
episode: 1200	finetune acc: 51.25000		test acc: 66.66667
episode: 1250	finetune acc: 42.50000		test acc: 72.91667
episode: 1300	finetune acc: 62.50000		test acc: 77.08333
episode: 1350	finetune acc: 42.50000		test acc: 52.08333
episode: 1400	finetune acc: 56.25000		test acc: 58.33333
episode: 1450	finetune acc: 42.50000		test acc: 64.58333
episode: 1500	finetune acc: 40.00000		test acc: 64.58333
episode: 1550	finetune acc: 55.00000		test acc: 70.83333
episode: 1600	finetune acc: 66.25000		test acc: 68.75000
episode: 1650	finetune acc: 66.25000		test acc: 72.91667
episode: 1700	finetune acc: 56.25000		test acc: 64.58333
episode: 1750	finetune acc: 57.50000		test acc: 68.75000
episode: 1800	finetune acc: 48.75000		test acc: 60.41667
episode: 1850	finetune acc: 62.50000		test acc: 58.33333
episode: 1900	finetune acc: 61.25000		test acc: 68.75000
episode: 1950	finetune acc: 62.50000		test acc: 68.75000
episode: 2000	finetune acc: 62.50000		test acc: 81.25000
episode: 2050	finetune acc: 55.00000		test acc: 70.83333
episode: 2100	finetune acc: 51.25000		test acc: 58.33333
episode: 2150	finetune acc: 51.25000		test acc: 72.91667
episode: 2200	finetune acc: 62.50000		test acc: 70.83333
episode: 2250	finetune acc: 52.50000		test acc: 60.41667
episode: 2300	finetune acc: 58.75000		test acc: 66.66667
episode: 2350	finetune acc: 67.50000		test acc: 68.75000
episode: 2400	finetune acc: 46.25000		test acc: 72.91667
episode: 2450	finetune acc: 65.00000		test acc: 70.83333
episode: 2500	finetune acc: 61.25000		test acc: 54.16667
episode: 2550	finetune acc: 67.50000		test acc: 64.58333
episode: 2600	finetune acc: 70.00000		test acc: 64.58333
episode: 2650	finetune acc: 67.50000		test acc: 70.83333
episode: 2700	finetune acc: 57.50000		test acc: 66.66667
episode: 2750	finetune acc: 53.75000		test acc: 60.41667
episode: 2800	finetune acc: 50.00000		test acc: 81.25000
episode: 2850	finetune acc: 62.50000		test acc: 64.58333
episode: 2900	finetune acc: 61.25000		test acc: 62.50000
episode: 2950	finetune acc: 57.50000		test acc: 68.75000
episode: 3000	finetune acc: 55.00000		test acc: 64.58333
episode: 3050	finetune acc: 52.50000		test acc: 68.75000
episode: 3100	finetune acc: 58.75000		test acc: 72.91667
episode: 3150	finetune acc: 70.00000		test acc: 64.58333
episode: 3200	finetune acc: 56.25000		test acc: 66.66667
episode: 3250	finetune acc: 68.75000		test acc: 72.91667
episode: 3300	finetune acc: 71.25000		test acc: 79.16667
episode: 3350	finetune acc: 70.00000		test acc: 66.66667
episode: 3400	finetune acc: 53.75000		test acc: 66.66667
episode: 3450	finetune acc: 58.75000		test acc: 68.75000
episode: 3500	finetune acc: 55.00000		test acc: 72.91667
episode: 3550	finetune acc: 58.75000		test acc: 62.50000
episode: 3600	finetune acc: 57.50000		test acc: 62.50000
episode: 3650	finetune acc: 73.75000		test acc: 58.33333
episode: 3700	finetune acc: 60.00000		test acc: 72.91667
episode: 3750	finetune acc: 65.00000		test acc: 68.75000
episode: 3800	finetune acc: 58.75000		test acc: 66.66667
episode: 3850	finetune acc: 55.00000		test acc: 64.58333
episode: 3900	finetune acc: 61.25000		test acc: 60.41667
episode: 3950	finetune acc: 67.50000		test acc: 75.00000
episode: 4000	finetune acc: 48.75000		test acc: 66.66667
episode: 4050	finetune acc: 53.75000		test acc: 68.75000
episode: 4100	finetune acc: 62.50000		test acc: 62.50000
episode: 4150	finetune acc: 41.25000		test acc: 81.25000
episode: 4200	finetune acc: 61.25000		test acc: 64.58333
episode: 4250	finetune acc: 57.50000		test acc: 62.50000
episode: 4300	finetune acc: 71.25000		test acc: 77.08333
episode: 4350	finetune acc: 53.75000		test acc: 62.50000
episode: 4400	finetune acc: 60.00000		test acc: 81.25000
episode: 4450	finetune acc: 57.50000		test acc: 70.83333
episode: 4500	finetune acc: 60.00000		test acc: 72.91667
episode: 4550	finetune acc: 65.00000		test acc: 64.58333
episode: 4600	finetune acc: 70.00000		test acc: 64.58333
episode: 4650	finetune acc: 68.75000		test acc: 60.41667
episode: 4700	finetune acc: 65.00000		test acc: 62.50000
episode: 4750	finetune acc: 73.75000		test acc: 68.75000
episode: 4800	finetune acc: 68.75000		test acc: 79.16667
episode: 4850	finetune acc: 57.50000		test acc: 66.66667
episode: 4900	finetune acc: 57.50000		test acc: 77.08333
episode: 4950	finetune acc: 65.00000		test acc: 62.50000
episode: 5000	finetune acc: 58.75000		test acc: 65.62500
episode: 5050	finetune acc: 63.75000		test acc: 59.37500
episode: 5100	finetune acc: 63.75000		test acc: 68.75000
episode: 5150	finetune acc: 66.25000		test acc: 64.06250
episode: 5200	finetune acc: 70.00000		test acc: 67.18750
episode: 5250	finetune acc: 60.00000		test acc: 71.87500
episode: 5300	finetune acc: 57.50000		test acc: 57.81250
episode: 5350	finetune acc: 55.00000		test acc: 71.87500
episode: 5400	finetune acc: 61.25000		test acc: 73.43750
episode: 5450	finetune acc: 66.25000		test acc: 73.43750
episode: 5500	finetune acc: 58.75000		test acc: 67.18750
episode: 5550	finetune acc: 58.75000		test acc: 70.31250
episode: 5600	finetune acc: 60.00000		test acc: 64.06250
episode: 5650	finetune acc: 61.25000		test acc: 73.43750
episode: 5700	finetune acc: 65.00000		test acc: 68.75000
episode: 5750	finetune acc: 62.50000		test acc: 60.93750
episode: 5800	finetune acc: 67.50000		test acc: 62.50000
episode: 5850	finetune acc: 61.25000		test acc: 67.18750
episode: 5900	finetune acc: 58.75000		test acc: 68.75000
episode: 5950	finetune acc: 58.75000		test acc: 64.06250
episode: 6000	finetune acc: 65.00000		test acc: 71.87500
episode: 6050	finetune acc: 66.25000		test acc: 71.87500
episode: 6100	finetune acc: 80.00000		test acc: 73.43750
episode: 6150	finetune acc: 62.50000		test acc: 65.62500
episode: 6200	finetune acc: 62.50000		test acc: 51.56250
episode: 6250	finetune acc: 68.75000		test acc: 65.62500
episode: 6300	finetune acc: 62.50000		test acc: 65.62500
episode: 6350	finetune acc: 70.00000		test acc: 73.43750
episode: 6400	finetune acc: 72.50000		test acc: 68.75000
episode: 6450	finetune acc: 73.75000		test acc: 71.87500
episode: 6500	finetune acc: 60.00000		test acc: 68.75000
episode: 6550	finetune acc: 65.00000		test acc: 76.56250
episode: 6600	finetune acc: 72.50000		test acc: 60.93750
episode: 6650	finetune acc: 56.25000		test acc: 62.50000
episode: 6700	finetune acc: 61.25000		test acc: 71.87500
episode: 6750	finetune acc: 78.75000		test acc: 71.87500
episode: 6800	finetune acc: 62.50000		test acc: 70.31250
episode: 6850	finetune acc: 71.25000		test acc: 62.50000
episode: 6900	finetune acc: 56.25000		test acc: 62.50000
episode: 6950	finetune acc: 61.25000		test acc: 65.62500
episode: 7000	finetune acc: 58.75000		test acc: 67.18750
episode: 7050	finetune acc: 67.50000		test acc: 68.75000
episode: 7100	finetune acc: 71.25000		test acc: 59.37500
episode: 7150	finetune acc: 71.25000		test acc: 64.06250
episode: 7200	finetune acc: 55.00000		test acc: 67.18750
episode: 7250	finetune acc: 63.75000		test acc: 65.62500
episode: 7300	finetune acc: 63.75000		test acc: 62.50000
episode: 7350	finetune acc: 65.00000		test acc: 59.37500
episode: 7400	finetune acc: 63.75000		test acc: 68.75000
episode: 7450	finetune acc: 62.50000		test acc: 67.18750
episode: 7500	finetune acc: 60.00000		test acc: 65.62500
episode: 7550	finetune acc: 58.75000		test acc: 60.93750
episode: 7600	finetune acc: 72.50000		test acc: 71.87500
episode: 7650	finetune acc: 67.50000		test acc: 75.00000
episode: 7700	finetune acc: 66.25000		test acc: 75.00000
episode: 7750	finetune acc: 58.75000		test acc: 57.81250
episode: 7800	finetune acc: 76.25000		test acc: 70.31250
episode: 7850	finetune acc: 72.50000		test acc: 76.56250
episode: 7900	finetune acc: 67.50000		test acc: 70.31250
episode: 7950	finetune acc: 65.00000		test acc: 67.18750
episode: 8000	finetune acc: 68.75000		test acc: 67.18750
episode: 8050	finetune acc: 62.50000		test acc: 68.75000
episode: 8100	finetune acc: 66.25000		test acc: 79.68750
episode: 8150	finetune acc: 62.50000		test acc: 65.62500
episode: 8200	finetune acc: 67.50000		test acc: 79.68750
episode: 8250	finetune acc: 66.25000		test acc: 76.56250
episode: 8300	finetune acc: 58.75000		test acc: 65.62500
episode: 8350	finetune acc: 52.50000		test acc: 67.18750
episode: 8400	finetune acc: 63.75000		test acc: 57.81250
episode: 8450	finetune acc: 61.25000		test acc: 75.00000
episode: 8500	finetune acc: 62.50000		test acc: 70.31250
episode: 8550	finetune acc: 76.25000		test acc: 78.12500
episode: 8600	finetune acc: 58.75000		test acc: 79.68750
episode: 8650	finetune acc: 65.00000		test acc: 65.62500
episode: 8700	finetune acc: 75.00000		test acc: 73.43750
episode: 8750	finetune acc: 67.50000		test acc: 60.93750
episode: 8800	finetune acc: 65.00000		test acc: 71.87500
episode: 8850	finetune acc: 71.25000		test acc: 70.31250
episode: 8900	finetune acc: 62.50000		test acc: 71.87500
episode: 8950	finetune acc: 76.25000		test acc: 75.00000
episode: 9000	finetune acc: 78.75000		test acc: 59.37500
episode: 9050	finetune acc: 65.00000		test acc: 59.37500
episode: 9100	finetune acc: 67.50000		test acc: 51.56250
episode: 9150	finetune acc: 80.00000		test acc: 64.06250
episode: 9200	finetune acc: 52.50000		test acc: 57.81250
episode: 9250	finetune acc: 62.50000		test acc: 67.18750
episode: 9300	finetune acc: 66.25000		test acc: 65.62500
episode: 9350	finetune acc: 66.25000		test acc: 68.75000
episode: 9400	finetune acc: 65.00000		test acc: 73.43750
episode: 9450	finetune acc: 67.50000		test acc: 71.87500
episode: 9500	finetune acc: 66.25000		test acc: 70.31250
episode: 9550	finetune acc: 57.50000		test acc: 57.81250
episode: 9600	finetune acc: 62.50000		test acc: 60.93750
episode: 9650	finetune acc: 68.75000		test acc: 75.00000
episode: 9700	finetune acc: 62.50000		test acc: 68.75000
episode: 9750	finetune acc: 60.00000		test acc: 67.18750
episode: 9800	finetune acc: 76.25000		test acc: 79.68750
episode: 9850	finetune acc: 58.75000		test acc: 62.50000
episode: 9900	finetune acc: 70.00000		test acc: 67.18750
episode: 9950	finetune acc: 72.50000		test acc: 78.12500
episode: 10000	finetune acc: 65.00000		test acc: 70.00000
episode: 10050	finetune acc: 58.75000		test acc: 68.75000
episode: 10100	finetune acc: 72.50000		test acc: 67.50000
episode: 10150	finetune acc: 66.25000		test acc: 77.50000
episode: 10200	finetune acc: 60.00000		test acc: 78.75000
episode: 10250	finetune acc: 63.75000		test acc: 70.00000
episode: 10300	finetune acc: 78.75000		test acc: 52.50000
episode: 10350	finetune acc: 72.50000		test acc: 75.00000
episode: 10400	finetune acc: 70.00000		test acc: 78.75000
episode: 10450	finetune acc: 66.25000		test acc: 66.25000
episode: 10500	finetune acc: 63.75000		test acc: 62.50000
episode: 10550	finetune acc: 55.00000		test acc: 66.25000
episode: 10600	finetune acc: 71.25000		test acc: 65.00000
episode: 10650	finetune acc: 70.00000		test acc: 62.50000
episode: 10700	finetune acc: 71.25000		test acc: 65.00000
episode: 10750	finetune acc: 73.75000		test acc: 70.00000
episode: 10800	finetune acc: 72.50000		test acc: 70.00000
episode: 10850	finetune acc: 57.50000		test acc: 72.50000
episode: 10900	finetune acc: 72.50000		test acc: 65.00000
episode: 10950	finetune acc: 58.75000		test acc: 71.25000
episode: 11000	finetune acc: 67.50000		test acc: 65.00000
episode: 11050	finetune acc: 63.75000		test acc: 70.00000
episode: 11100	finetune acc: 72.50000		test acc: 67.50000
episode: 11150	finetune acc: 61.25000		test acc: 73.75000
episode: 11200	finetune acc: 68.75000		test acc: 65.00000
episode: 11250	finetune acc: 70.00000		test acc: 73.75000
episode: 11300	finetune acc: 70.00000		test acc: 68.75000
episode: 11350	finetune acc: 72.50000		test acc: 71.25000
episode: 11400	finetune acc: 67.50000		test acc: 68.75000
episode: 11450	finetune acc: 67.50000		test acc: 68.75000
episode: 11500	finetune acc: 71.25000		test acc: 67.50000
episode: 11550	finetune acc: 60.00000		test acc: 71.25000
episode: 11600	finetune acc: 75.00000		test acc: 66.25000
episode: 11650	finetune acc: 70.00000		test acc: 61.25000
episode: 11700	finetune acc: 65.00000		test acc: 71.25000
episode: 11750	finetune acc: 62.50000		test acc: 72.50000
episode: 11800	finetune acc: 58.75000		test acc: 66.25000
episode: 11850	finetune acc: 66.25000		test acc: 68.75000
episode: 11900	finetune acc: 72.50000		test acc: 73.75000
episode: 11950	finetune acc: 68.75000		test acc: 73.75000
episode: 12000	finetune acc: 65.00000		test acc: 68.75000
episode: 12050	finetune acc: 66.25000		test acc: 62.50000
episode: 12100	finetune acc: 76.25000		test acc: 62.50000
episode: 12150	finetune acc: 78.75000		test acc: 67.50000
episode: 12200	finetune acc: 70.00000		test acc: 71.25000
episode: 12250	finetune acc: 77.50000		test acc: 75.00000
episode: 12300	finetune acc: 66.25000		test acc: 71.25000
episode: 12350	finetune acc: 77.50000		test acc: 68.75000
episode: 12400	finetune acc: 65.00000		test acc: 62.50000
episode: 12450	finetune acc: 75.00000		test acc: 68.75000
episode: 12500	finetune acc: 71.25000		test acc: 76.25000
episode: 12550	finetune acc: 75.00000		test acc: 75.00000
episode: 12600	finetune acc: 66.25000		test acc: 68.75000
episode: 12650	finetune acc: 66.25000		test acc: 70.00000
episode: 12700	finetune acc: 82.50000		test acc: 78.75000
episode: 12750	finetune acc: 73.75000		test acc: 63.75000
episode: 12800	finetune acc: 72.50000		test acc: 70.00000
episode: 12850	finetune acc: 65.00000		test acc: 76.25000
episode: 12900	finetune acc: 67.50000		test acc: 70.00000
episode: 12950	finetune acc: 73.75000		test acc: 75.00000
episode: 13000	finetune acc: 56.25000		test acc: 65.00000
episode: 13050	finetune acc: 70.00000		test acc: 65.00000
episode: 13100	finetune acc: 70.00000		test acc: 65.00000
episode: 13150	finetune acc: 60.00000		test acc: 67.50000
episode: 13200	finetune acc: 66.25000		test acc: 73.75000
episode: 13250	finetune acc: 68.75000		test acc: 68.75000
episode: 13300	finetune acc: 76.25000		test acc: 53.75000
episode: 13350	finetune acc: 68.75000		test acc: 62.50000
episode: 13400	finetune acc: 72.50000		test acc: 66.25000
episode: 13450	finetune acc: 68.75000		test acc: 68.75000
episode: 13500	finetune acc: 81.25000		test acc: 67.50000
episode: 13550	finetune acc: 66.25000		test acc: 67.50000
episode: 13600	finetune acc: 71.25000		test acc: 66.25000
episode: 13650	finetune acc: 71.25000		test acc: 71.25000
episode: 13700	finetune acc: 65.00000		test acc: 75.00000
episode: 13750	finetune acc: 76.25000		test acc: 73.75000
episode: 13800	finetune acc: 58.75000		test acc: 77.50000
episode: 13850	finetune acc: 73.75000		test acc: 73.75000
episode: 13900	finetune acc: 73.75000		test acc: 81.25000
episode: 13950	finetune acc: 76.25000		test acc: 73.75000
episode: 14000	finetune acc: 72.50000		test acc: 68.75000
episode: 14050	finetune acc: 66.25000		test acc: 76.25000
episode: 14100	finetune acc: 66.25000		test acc: 65.00000
episode: 14150	finetune acc: 73.75000		test acc: 75.00000
episode: 14200	finetune acc: 71.25000		test acc: 72.50000
episode: 14250	finetune acc: 70.00000		test acc: 75.00000
episode: 14300	finetune acc: 60.00000		test acc: 65.00000
episode: 14350	finetune acc: 73.75000		test acc: 67.50000
episode: 14400	finetune acc: 67.50000		test acc: 65.00000
episode: 14450	finetune acc: 72.50000		test acc: 73.75000
episode: 14500	finetune acc: 70.00000		test acc: 70.00000
episode: 14550	finetune acc: 66.25000		test acc: 72.50000
episode: 14600	finetune acc: 72.50000		test acc: 72.50000
episode: 14650	finetune acc: 71.25000		test acc: 70.00000
episode: 14700	finetune acc: 72.50000		test acc: 70.00000
episode: 14750	finetune acc: 67.50000		test acc: 62.50000
episode: 14800	finetune acc: 68.75000		test acc: 63.75000
episode: 14850	finetune acc: 73.75000		test acc: 71.25000
episode: 14900	finetune acc: 67.50000		test acc: 71.25000
episode: 14950	finetune acc: 70.00000		test acc: 83.75000
episode: 15000	finetune acc: 65.00000		test acc: 66.66667
episode: 15050	finetune acc: 70.00000		test acc: 69.79167
episode: 15100	finetune acc: 63.75000		test acc: 73.95833
episode: 15150	finetune acc: 71.25000		test acc: 77.08333
episode: 15200	finetune acc: 62.50000		test acc: 75.00000
episode: 15250	finetune acc: 65.00000		test acc: 82.29167
episode: 15300	finetune acc: 75.00000		test acc: 82.29167
episode: 15350	finetune acc: 68.75000		test acc: 68.75000
episode: 15400	finetune acc: 62.50000		test acc: 73.95833
episode: 15450	finetune acc: 70.00000		test acc: 72.91667
episode: 15500	finetune acc: 73.75000		test acc: 75.00000
episode: 15550	finetune acc: 60.00000		test acc: 71.87500
episode: 15600	finetune acc: 61.25000		test acc: 69.79167
episode: 15650	finetune acc: 60.00000		test acc: 70.83333
episode: 15700	finetune acc: 71.25000		test acc: 67.70833
episode: 15750	finetune acc: 80.00000		test acc: 69.79167
episode: 15800	finetune acc: 76.25000		test acc: 67.70833
episode: 15850	finetune acc: 65.00000		test acc: 72.91667
episode: 15900	finetune acc: 72.50000		test acc: 68.75000
episode: 15950	finetune acc: 60.00000		test acc: 66.66667
episode: 16000	finetune acc: 75.00000		test acc: 72.91667
episode: 16050	finetune acc: 67.50000		test acc: 71.87500
episode: 16100	finetune acc: 77.50000		test acc: 69.79167
episode: 16150	finetune acc: 70.00000		test acc: 70.83333
episode: 16200	finetune acc: 63.75000		test acc: 70.83333
episode: 16250	finetune acc: 73.75000		test acc: 69.79167
episode: 16300	finetune acc: 70.00000		test acc: 65.62500
episode: 16350	finetune acc: 68.75000		test acc: 72.91667
episode: 16400	finetune acc: 66.25000		test acc: 64.58333
episode: 16450	finetune acc: 75.00000		test acc: 65.62500
episode: 16500	finetune acc: 72.50000		test acc: 70.83333
episode: 16550	finetune acc: 67.50000		test acc: 69.79167
episode: 16600	finetune acc: 77.50000		test acc: 75.00000
episode: 16650	finetune acc: 68.75000		test acc: 65.62500
episode: 16700	finetune acc: 75.00000		test acc: 64.58333
episode: 16750	finetune acc: 63.75000		test acc: 67.70833
episode: 16800	finetune acc: 76.25000		test acc: 70.83333
episode: 16850	finetune acc: 75.00000		test acc: 64.58333
episode: 16900	finetune acc: 63.75000		test acc: 73.95833
episode: 16950	finetune acc: 73.75000		test acc: 76.04167
episode: 17000	finetune acc: 76.25000		test acc: 71.87500
episode: 17050	finetune acc: 75.00000		test acc: 71.87500
episode: 17100	finetune acc: 67.50000		test acc: 66.66667
episode: 17150	finetune acc: 77.50000		test acc: 73.95833
episode: 17200	finetune acc: 67.50000		test acc: 80.20833
episode: 17250	finetune acc: 70.00000		test acc: 73.95833
episode: 17300	finetune acc: 58.75000		test acc: 75.00000
episode: 17350	finetune acc: 68.75000		test acc: 62.50000
episode: 17400	finetune acc: 75.00000		test acc: 76.04167
episode: 17450	finetune acc: 71.25000		test acc: 75.00000
episode: 17500	finetune acc: 72.50000		test acc: 71.87500
episode: 17550	finetune acc: 67.50000		test acc: 75.00000
episode: 17600	finetune acc: 75.00000		test acc: 71.87500
episode: 17650	finetune acc: 66.25000		test acc: 69.79167
episode: 17700	finetune acc: 75.00000		test acc: 62.50000
episode: 17750	finetune acc: 67.50000		test acc: 69.79167
episode: 17800	finetune acc: 68.75000		test acc: 73.95833
episode: 17850	finetune acc: 76.25000		test acc: 75.00000
episode: 17900	finetune acc: 75.00000		test acc: 71.87500
episode: 17950	finetune acc: 66.25000		test acc: 70.83333
episode: 18000	finetune acc: 72.50000		test acc: 72.91667
episode: 18050	finetune acc: 75.00000		test acc: 76.04167
episode: 18100	finetune acc: 63.75000		test acc: 59.37500
episode: 18150	finetune acc: 66.25000		test acc: 69.79167
episode: 18200	finetune acc: 78.75000		test acc: 67.70833
episode: 18250	finetune acc: 63.75000		test acc: 75.00000
episode: 18300	finetune acc: 73.75000		test acc: 69.79167
episode: 18350	finetune acc: 81.25000		test acc: 73.95833
episode: 18400	finetune acc: 85.00000		test acc: 72.91667
episode: 18450	finetune acc: 72.50000		test acc: 62.50000
episode: 18500	finetune acc: 71.25000		test acc: 70.83333
episode: 18550	finetune acc: 77.50000		test acc: 77.08333
episode: 18600	finetune acc: 80.00000		test acc: 76.04167
episode: 18650	finetune acc: 62.50000		test acc: 60.41667
episode: 18700	finetune acc: 78.75000		test acc: 67.70833
episode: 18750	finetune acc: 67.50000		test acc: 62.50000
episode: 18800	finetune acc: 72.50000		test acc: 76.04167
episode: 18850	finetune acc: 72.50000		test acc: 67.70833
episode: 18900	finetune acc: 68.75000		test acc: 77.08333
episode: 18950	finetune acc: 61.25000		test acc: 79.16667
episode: 19000	finetune acc: 70.00000		test acc: 70.83333
episode: 19050	finetune acc: 65.00000		test acc: 71.87500
episode: 19100	finetune acc: 78.75000		test acc: 72.91667
episode: 19150	finetune acc: 72.50000		test acc: 75.00000
episode: 19200	finetune acc: 76.25000		test acc: 68.75000
episode: 19250	finetune acc: 68.75000		test acc: 72.91667
episode: 19300	finetune acc: 72.50000		test acc: 73.95833
episode: 19350	finetune acc: 77.50000		test acc: 68.75000
episode: 19400	finetune acc: 63.75000		test acc: 71.87500
episode: 19450	finetune acc: 72.50000		test acc: 72.91667
episode: 19500	finetune acc: 76.25000		test acc: 68.75000
episode: 19550	finetune acc: 66.25000		test acc: 69.79167
episode: 19600	finetune acc: 73.75000		test acc: 77.08333
episode: 19650	finetune acc: 68.75000		test acc: 64.58333
episode: 19700	finetune acc: 67.50000		test acc: 78.12500
episode: 19750	finetune acc: 81.25000		test acc: 73.95833
episode: 19800	finetune acc: 82.50000		test acc: 71.87500
episode: 19850	finetune acc: 77.50000		test acc: 67.70833
episode: 19900	finetune acc: 81.25000		test acc: 79.16667
episode: 19950	finetune acc: 72.50000		test acc: 70.83333

Evaluate on train subjects:
0-shot accuracy on subject 1: 	mean: 76.388889%	std: 9.894310%
0-shot accuracy on subject 2: 	mean: 58.506944%	std: 11.613792%
0-shot accuracy on subject 4: 	mean: 69.270833%	std: 10.661192%
0-shot accuracy on subject 5: 	mean: 59.201389%	std: 12.367888%
0-shot accuracy on subject 6: 	mean: 67.013889%	std: 12.113030%
0-shot accuracy on subject 7: 	mean: 77.777778%	std: 10.146972%
0-shot accuracy on subject 8: 	mean: 79.340278%	std: 12.656953%
0-shot accuracy on subject 9: 	mean: 72.395833%	std: 11.060813%
Validation Accuracy: [1 : nan] [2 : nan] [3 : 85.71429] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.44832] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.72428] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 1: 	validation acc: 85.71429	validation loss: 0.448318	train loss: 0.724276
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.38202] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.54850] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 2: 	validation acc: 87.50000	validation loss: 0.382020	train loss: 0.548503
Validation Accuracy: [1 : nan] [2 : nan] [3 : 86.60714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.34912] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.51522] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 3: 	validation acc: 86.60714	validation loss: 0.349115	train loss: 0.515220
Validation Accuracy: [1 : nan] [2 : nan] [3 : 86.60714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.32739] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.46430] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 4: 	validation acc: 86.60714	validation loss: 0.327389	train loss: 0.464297
Validation Accuracy: [1 : nan] [2 : nan] [3 : 87.50000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.31341] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.45913] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 5: 	validation acc: 87.50000	validation loss: 0.313415	train loss: 0.459131
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.29640] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.40270] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 6: 	validation acc: 88.39286	validation loss: 0.296397	train loss: 0.402702
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.27676] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.35229] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 7: 	validation acc: 89.28571	validation loss: 0.276763	train loss: 0.352290
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.26393] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.34346] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 8: 	validation acc: 90.17857	validation loss: 0.263932	train loss: 0.343460
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.25981] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.34291] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 9: 	validation acc: 90.17857	validation loss: 0.259808	train loss: 0.342909
Validation Accuracy: [1 : nan] [2 : nan] [3 : 88.39286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.25941] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.31633] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 10: 	validation acc: 88.39286	validation loss: 0.259410	train loss: 0.316331
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.25944] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.30413] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 11: 	validation acc: 89.28571	validation loss: 0.259440	train loss: 0.304131
Validation Accuracy: [1 : nan] [2 : nan] [3 : 89.28571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.25209] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.28612] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 12: 	validation acc: 89.28571	validation loss: 0.252086	train loss: 0.286118
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.07143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.23070] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.29212] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 13: 	validation acc: 91.07143	validation loss: 0.230701	train loss: 0.292119
Validation Accuracy: [1 : nan] [2 : nan] [3 : 90.17857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.23343] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.25314] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 14: 	validation acc: 90.17857	validation loss: 0.233430	train loss: 0.253141
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.07143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.22753] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.24040] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 15: 	validation acc: 91.07143	validation loss: 0.227529	train loss: 0.240396
Validation Accuracy: [1 : nan] [2 : nan] [3 : 92.85714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.21836] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.23293] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 16: 	validation acc: 92.85714	validation loss: 0.218359	train loss: 0.232927
Validation Accuracy: [1 : nan] [2 : nan] [3 : 92.85714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.20550] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.21778] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 17: 	validation acc: 92.85714	validation loss: 0.205498	train loss: 0.217776
Validation Accuracy: [1 : nan] [2 : nan] [3 : 92.85714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.19448] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.21195] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 18: 	validation acc: 92.85714	validation loss: 0.194476	train loss: 0.211948
Validation Accuracy: [1 : nan] [2 : nan] [3 : 92.85714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.18928] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.17641] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 19: 	validation acc: 92.85714	validation loss: 0.189284	train loss: 0.176414
Validation Accuracy: [1 : nan] [2 : nan] [3 : 92.85714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.19882] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.20076] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 20: 	validation acc: 92.85714	validation loss: 0.198817	train loss: 0.200757
Validation Accuracy: [1 : nan] [2 : nan] [3 : 92.85714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.20307] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.21689] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 21: 	validation acc: 92.85714	validation loss: 0.203074	train loss: 0.216890
Validation Accuracy: [1 : nan] [2 : nan] [3 : 92.85714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.18490] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.18950] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 22: 	validation acc: 92.85714	validation loss: 0.184898	train loss: 0.189498
Validation Accuracy: [1 : nan] [2 : nan] [3 : 93.75000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.17574] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.17982] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 23: 	validation acc: 93.75000	validation loss: 0.175739	train loss: 0.179820
Validation Accuracy: [1 : nan] [2 : nan] [3 : 92.85714] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.16880] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.18057] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 24: 	validation acc: 92.85714	validation loss: 0.168801	train loss: 0.180567
Validation Accuracy: [1 : nan] [2 : nan] [3 : 93.75000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.16622] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.19992] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 25: 	validation acc: 93.75000	validation loss: 0.166221	train loss: 0.199919
Validation Accuracy: [1 : nan] [2 : nan] [3 : 93.75000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.16525] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.16678] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 26: 	validation acc: 93.75000	validation loss: 0.165250	train loss: 0.166781
Validation Accuracy: [1 : nan] [2 : nan] [3 : 93.75000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.16026] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.16159] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 27: 	validation acc: 93.75000	validation loss: 0.160257	train loss: 0.161595
Validation Accuracy: [1 : nan] [2 : nan] [3 : 93.75000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.17113] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14577] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 28: 	validation acc: 93.75000	validation loss: 0.171133	train loss: 0.145768
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.16384] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.16042] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 29: 	validation acc: 94.64286	validation loss: 0.163842	train loss: 0.160416
Validation Accuracy: [1 : nan] [2 : nan] [3 : 91.07143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.16052] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.12670] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 30: 	validation acc: 91.07143	validation loss: 0.160519	train loss: 0.126696
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.14485] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.18087] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 31: 	validation acc: 94.64286	validation loss: 0.144846	train loss: 0.180867
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.14426] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.13155] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 32: 	validation acc: 94.64286	validation loss: 0.144262	train loss: 0.131552
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.14094] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.13695] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 33: 	validation acc: 95.53571	validation loss: 0.140939	train loss: 0.136955
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.13426] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14025] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 34: 	validation acc: 94.64286	validation loss: 0.134262	train loss: 0.140252
Validation Accuracy: [1 : nan] [2 : nan] [3 : 93.75000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.13838] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14216] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 35: 	validation acc: 93.75000	validation loss: 0.138376	train loss: 0.142159
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.13111] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.12624] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 36: 	validation acc: 94.64286	validation loss: 0.131110	train loss: 0.126238
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.11889] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.13273] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 37: 	validation acc: 94.64286	validation loss: 0.118887	train loss: 0.132726
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.11767] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14989] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 38: 	validation acc: 95.53571	validation loss: 0.117674	train loss: 0.149886
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.12105] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.11272] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 39: 	validation acc: 94.64286	validation loss: 0.121046	train loss: 0.112717
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.11880] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10833] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 40: 	validation acc: 94.64286	validation loss: 0.118802	train loss: 0.108328
Validation Accuracy: [1 : nan] [2 : nan] [3 : 93.75000] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.11744] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09252] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 41: 	validation acc: 93.75000	validation loss: 0.117439	train loss: 0.092519
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.11930] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.12994] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 42: 	validation acc: 94.64286	validation loss: 0.119300	train loss: 0.129942
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.11795] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10484] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 43: 	validation acc: 94.64286	validation loss: 0.117948	train loss: 0.104837
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10422] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09179] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 44: 	validation acc: 94.64286	validation loss: 0.104223	train loss: 0.091794
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10420] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09622] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 45: 	validation acc: 95.53571	validation loss: 0.104197	train loss: 0.096217
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09788] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 46: 	validation acc: 95.53571	validation loss: 0.102861	train loss: 0.097880
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.11326] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.11907] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 47: 	validation acc: 95.53571	validation loss: 0.113260	train loss: 0.119074
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10972] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07801] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 48: 	validation acc: 96.42857	validation loss: 0.109725	train loss: 0.078012
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10817] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08513] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 49: 	validation acc: 95.53571	validation loss: 0.108171	train loss: 0.085125
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10318] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08595] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 50: 	validation acc: 95.53571	validation loss: 0.103181	train loss: 0.085948
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09834] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.11394] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 51: 	validation acc: 95.53571	validation loss: 0.098345	train loss: 0.113938
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09406] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08114] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 52: 	validation acc: 96.42857	validation loss: 0.094061	train loss: 0.081135
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09457] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08203] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 53: 	validation acc: 96.42857	validation loss: 0.094571	train loss: 0.082026
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09886] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07547] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 54: 	validation acc: 95.53571	validation loss: 0.098860	train loss: 0.075474
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10399] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07890] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 55: 	validation acc: 95.53571	validation loss: 0.103990	train loss: 0.078902
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09979] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.11404] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 56: 	validation acc: 95.53571	validation loss: 0.099787	train loss: 0.114041
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09696] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09480] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 57: 	validation acc: 97.32143	validation loss: 0.096963	train loss: 0.094803
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09171] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07192] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 58: 	validation acc: 97.32143	validation loss: 0.091712	train loss: 0.071922
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08953] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10275] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 59: 	validation acc: 97.32143	validation loss: 0.089531	train loss: 0.102754
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09319] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10796] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 60: 	validation acc: 95.53571	validation loss: 0.093189	train loss: 0.107958
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09756] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.11072] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 61: 	validation acc: 95.53571	validation loss: 0.097560	train loss: 0.110723
Validation Accuracy: [1 : nan] [2 : nan] [3 : 94.64286] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.11558] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06969] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 62: 	validation acc: 94.64286	validation loss: 0.115580	train loss: 0.069688
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10909] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09856] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 63: 	validation acc: 95.53571	validation loss: 0.109092	train loss: 0.098562
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09451] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08901] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 64: 	validation acc: 97.32143	validation loss: 0.094510	train loss: 0.089008
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.05872] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 65: 	validation acc: 97.32143	validation loss: 0.088567	train loss: 0.058715
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09132] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08433] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 66: 	validation acc: 96.42857	validation loss: 0.091323	train loss: 0.084333
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08937] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07011] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 67: 	validation acc: 97.32143	validation loss: 0.089374	train loss: 0.070111
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09163] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07775] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 68: 	validation acc: 97.32143	validation loss: 0.091628	train loss: 0.077751
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08327] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06133] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 69: 	validation acc: 96.42857	validation loss: 0.083268	train loss: 0.061327
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08851] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08953] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 70: 	validation acc: 95.53571	validation loss: 0.088512	train loss: 0.089531
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09288] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.10604] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 71: 	validation acc: 96.42857	validation loss: 0.092878	train loss: 0.106037
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09338] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06879] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 72: 	validation acc: 96.42857	validation loss: 0.093375	train loss: 0.068792
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10658] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07524] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 73: 	validation acc: 97.32143	validation loss: 0.106584	train loss: 0.075240
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10272] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06574] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 74: 	validation acc: 95.53571	validation loss: 0.102724	train loss: 0.065737
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10080] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08391] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 75: 	validation acc: 96.42857	validation loss: 0.100797	train loss: 0.083914
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10701] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06280] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 76: 	validation acc: 96.42857	validation loss: 0.107007	train loss: 0.062797
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09871] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.14541] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 77: 	validation acc: 97.32143	validation loss: 0.098710	train loss: 0.145414
Validation Accuracy: [1 : nan] [2 : nan] [3 : 95.53571] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09360] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06282] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 78: 	validation acc: 95.53571	validation loss: 0.093599	train loss: 0.062825
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08610] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06078] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 79: 	validation acc: 96.42857	validation loss: 0.086098	train loss: 0.060785
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08694] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08132] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 80: 	validation acc: 96.42857	validation loss: 0.086941	train loss: 0.081322
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08198] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07520] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 81: 	validation acc: 96.42857	validation loss: 0.081985	train loss: 0.075197
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09128] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06446] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 82: 	validation acc: 97.32143	validation loss: 0.091278	train loss: 0.064456
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09152] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07641] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 83: 	validation acc: 97.32143	validation loss: 0.091517	train loss: 0.076410
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09468] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06106] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 84: 	validation acc: 97.32143	validation loss: 0.094678	train loss: 0.061059
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09169] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06233] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 85: 	validation acc: 97.32143	validation loss: 0.091690	train loss: 0.062329
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09260] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06121] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 86: 	validation acc: 97.32143	validation loss: 0.092600	train loss: 0.061207
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09300] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.05300] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 87: 	validation acc: 97.32143	validation loss: 0.093005	train loss: 0.053001
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10253] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06443] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 88: 	validation acc: 97.32143	validation loss: 0.102534	train loss: 0.064431
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10240] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06794] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 89: 	validation acc: 97.32143	validation loss: 0.102397	train loss: 0.067941
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10723] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.07599] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 90: 	validation acc: 97.32143	validation loss: 0.107235	train loss: 0.075985
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10416] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06882] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 91: 	validation acc: 97.32143	validation loss: 0.104164	train loss: 0.068823
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.09920] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.05814] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 92: 	validation acc: 96.42857	validation loss: 0.099205	train loss: 0.058143
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.10603] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.05514] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 93: 	validation acc: 96.42857	validation loss: 0.106028	train loss: 0.055136
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08951] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.05969] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 94: 	validation acc: 97.32143	validation loss: 0.089509	train loss: 0.059686
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.07976] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.09990] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 95: 	validation acc: 96.42857	validation loss: 0.079760	train loss: 0.099902
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08276] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.04449] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 96: 	validation acc: 96.42857	validation loss: 0.082760	train loss: 0.044486
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.07399] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06253] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 97: 	validation acc: 96.42857	validation loss: 0.073988	train loss: 0.062530
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.07808] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.05732] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 98: 	validation acc: 97.32143	validation loss: 0.078079	train loss: 0.057325
Validation Accuracy: [1 : nan] [2 : nan] [3 : 97.32143] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.08509] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.06475] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 99: 	validation acc: 97.32143	validation loss: 0.085093	train loss: 0.064754
Validation Accuracy: [1 : nan] [2 : nan] [3 : 96.42857] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
validation loss: [1 : nan] [2 : nan] [3 : 0.11337] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
train loss: [1 : nan] [2 : nan] [3 : 0.08306] [4 : nan] [5 : nan] [6 : nan] [7 : nan] [8 : nan] [9 : nan]
Epoch 100: 	validation acc: 96.42857	validation loss: 0.113374	train loss: 0.083056
